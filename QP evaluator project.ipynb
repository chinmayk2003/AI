{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "978ba3b5-94fa-43e2-a53f-ee1167f0819a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Sep - 2023.pdf \n",
      "\n",
      "Total No. of Questions : 4]\n",
      "[Total No. of Pages : 1\n",
      "[6188]-290\n",
      "B.E. (A. I. D. S.) (Insem.)\n",
      "MACHINE LEARNING\n",
      "(2019 Pattern) (Semester - VII) (417521)\n",
      "Time : 1 Hour]\n",
      "[Max. Marks : 30\n",
      "Instructions to the candidates :\n",
      "1)\n",
      "Answers Q.1 or Q.2, Q.3 or Q.4.\n",
      "2)\n",
      "Make suitable diagram wherever necessary.\n",
      "3)\n",
      "Figure to the right indicate full marks.\n",
      "4)\n",
      "Assume suitable data if necessary.\n",
      "P-5321\n",
      "Q1) a)\n",
      "Compare Machine Learning with Traditional. programming.\n",
      "[5]\n",
      "b)\n",
      "What is Dimensionality Reduction, Explain any one Dimensionality\n",
      "Reduction technique.\n",
      "[6]\n",
      "c)\n",
      "Write a note on Reinforcement Learning.\n",
      "[4]\n",
      "OR\n",
      "Q2) a)\n",
      "Explain parametric & nonparametric models in machine learning.\n",
      "[5]\n",
      "b)\n",
      "Differentiate supervised and unsupervised learning techniques.\n",
      "[5]\n",
      "c)\n",
      "Elaborate grouping and grading models.\n",
      "[5]\n",
      "Q3) a)\n",
      "Elaborate random forest regression.\n",
      "[5]\n",
      "b)\n",
      "Differentiate multivariate regression and univariate regression.\n",
      "[4]\n",
      "c)\n",
      "Define Regression. Explain types of regression.\n",
      "[6]\n",
      "OR\n",
      "Q4) a)\n",
      "What is underfitting and overfitting in machine Learning explain the\n",
      "techniques to reduce overfitting?\n",
      " [5]\n",
      "b)\n",
      "Explain any two Evaluation Metrics for regression.\n",
      "[5]\n",
      "c)\n",
      "Explain Elastic Net regression in Machine Learning.\n",
      "[5]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SEAT No. :\n",
      "CEGP013091\n",
      "49.248.216.238 04/09/2023 13:59:27 static-238\n",
      "CEGP013091\n",
      "49.248.216.238 04/09/2023 13:59:27 static-238\n",
      "CEGP013091\n",
      "49.248.216.238 04/09/2023 13:59:27 static-238\n",
      "\n",
      "\n",
      " Sept- 2024.pdf \n",
      "\n",
      "Total No. of Questions : 4]\n",
      "[Total No. of Pages : 1\n",
      "[6361]-188\n",
      "B.E. (AIDS) (Insem.)\n",
      "MACHINE LEARNING\n",
      "(2019 Pattern) (Semester - VII) (417521)\n",
      "Time : 1 Hour]\n",
      "[Max. Marks : 30\n",
      "Instructions to the candidates :\n",
      "1)\n",
      "Answer Q.1 or Q.2, Q.3 or Q.4.\n",
      "2)\n",
      "Make suitable diagram wherever necessary.\n",
      "3)\n",
      "Figures to the right indicate full marks.\n",
      "4)\n",
      "Assume suitable data, if necessary.\n",
      "PC-316\n",
      "Q1) a)\n",
      "Describe Machine Learning and differentiate it from traditional\n",
      "programming.\n",
      "[6]\n",
      "b)\n",
      "Explain Principal Component Analysis used in Machine Learning.\n",
      "[5]\n",
      "c)\n",
      "Explain the relationship between Artificial Intelligence, Machine Learning\n",
      "and data science.\n",
      "[4]\n",
      "OR\n",
      "Q2) a)\n",
      "Explain types of Machine Learning.\n",
      "[6]\n",
      "b)\n",
      "Explain Linear Discriminant Analysis (LDA) used in Machine Learning.[5]\n",
      "c)\n",
      "Differentiate Grouping and Grading models of Machine Learning.\n",
      "[4]\n",
      "Q3) a)\n",
      "Explain three evaluation metrics used for regression model.\n",
      "[6]\n",
      "b)\n",
      "Explain the Random forest Regression.\n",
      "[5]\n",
      "c)\n",
      "Differentiate between Regression and Correlation.\n",
      "[4]\n",
      "OR\n",
      "Q4) a)\n",
      "What is Regression? Explain types of Regressions.\n",
      "[6]\n",
      "b)\n",
      "Explain Bias-Variance Trade-off with respect to Machine Learning.\n",
      "[5]\n",
      "c)\n",
      "Differentiate Ridge and Lasso Regression techniques.\n",
      "[4]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SEAT No. :\n",
      "CEGP013091\n",
      "49.248.216.238 31/08/2024 13:38:08 static-238\n",
      "CEGP013091\n",
      "49.248.216.238 31/08/2024 13:38:08 static-238\n",
      "CEGP013091\n",
      "49.248.216.238 31/08/2024 13:38:08 static-238\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "import easyocr\n",
    "import docx\n",
    "import fitz \n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "file_paths = filedialog.askopenfilenames(title=\"Select files (PDF/DOCX/Image)\")\n",
    "\n",
    "all_text = \"\"\n",
    "\n",
    "def extract_text_from_pdf(file_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        doc = fitz.open(file_path)\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    except:\n",
    "        text = \"OCR fallback: \"\n",
    "        images = convert_pdf_to_images(file_path)\n",
    "        for img in images:\n",
    "            text += pytesseract.image_to_string(img)\n",
    "    return text\n",
    "\n",
    "def convert_pdf_to_images(pdf_path):\n",
    "    import fitz\n",
    "    doc = fitz.open(pdf_path)\n",
    "    images = []\n",
    "    for page in doc:\n",
    "        pix = page.get_pixmap()\n",
    "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "def extract_text_from_docx(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    return \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "def extract_text_from_image(file_path):\n",
    "    try:\n",
    "        return reader.readtext(file_path, detail=0, paragraph=True)\n",
    "    except:\n",
    "        return [pytesseract.image_to_string(Image.open(file_path))]\n",
    "\n",
    "for file_path in file_paths:\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "    text = \"\"\n",
    "    if ext == \".pdf\":\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    elif ext == \".docx\":\n",
    "        text = extract_text_from_docx(file_path)\n",
    "    elif ext in [\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\"]:\n",
    "        text = \"\\n\".join(extract_text_from_image(file_path))\n",
    "    else:\n",
    "        continue \n",
    "    \n",
    "    clean_text = f\"\\n\\n {os.path.basename(file_path)} \\n\\n{text}\"\n",
    "    all_text += clean_text\n",
    "\n",
    "print(all_text[:5000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cd97ddd-9094-4435-8005-2fa85b0e1714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Make Suitable Diagram Wherever Necessary (score: 22.0)\n",
      "2. Right Indicate Full Marks (score: 14.5)\n",
      "3. One Dimensionality Reduction Technique (score: 14.0)\n",
      "4. Elaborate Random Forest Regression (score: 12.25)\n",
      "5. Two Evaluation Metrics (score: 11.0)\n",
      "6. Assume Suitable Data (score: 9.67)\n",
      "7. Random Forest Regression (score: 9.25)\n",
      "8. 6361 ]- B (score: 8.2)\n",
      "9. 6188 ]- B (score: 8.2)\n",
      "10. Q ., Q (score: 8.0)\n",
      "11. Unsupervised Learning Techniques (score: 7.6)\n",
      "12. Lasso Regression Techniques (score: 7.58)\n",
      "13. Describe Machine Learning (score: 7.5)\n",
      "14. Compare Machine Learning (score: 7.5)\n",
      "15. Differentiate Multivariate Regression (score: 7.08)\n",
      "16. Dimensionality Reduction (score: 6.0)\n",
      "17. Elaborate Grouping (score: 5.0)\n",
      "18. Data Science (score: 4.67)\n",
      "19. Q .. (score: 4.5)\n",
      "20. Answers Q (score: 4.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chinm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chinm\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "combined_text = \"\\n\".join(all_text if isinstance(all_text, list) else [all_text])\n",
    "\n",
    "cleaned_text = combined_text\n",
    "cleaned_text = re.sub(r'[\\n\\r\\t]+', ' ', cleaned_text)\n",
    "cleaned_text = re.sub(r'[•●▪]', ' ', cleaned_text)\n",
    "cleaned_text = re.sub(r'\\s{2,}', ' ', cleaned_text)\n",
    "cleaned_text = re.sub(r'\\bPage\\s+\\d+\\b', '', cleaned_text, flags=re.I)\n",
    "cleaned_text = re.sub(r'\\b\\d{1,3}\\b', '', cleaned_text)\n",
    "\n",
    "rake = Rake()\n",
    "rake.extract_keywords_from_text(cleaned_text)\n",
    "ranked_phrases = rake.get_ranked_phrases_with_scores()\n",
    "\n",
    "invalid_keywords = {\"explain\", \"write\", \"short notes\", \"question\", \"note\", \"pages\", \"total\", \"seat\", \"section\"}\n",
    "\n",
    "valid_topics = []\n",
    "for score, phrase in ranked_phrases:\n",
    "    phrase = phrase.strip().title()\n",
    "    if (2 <= len(phrase.split()) <= 5) and not any(bad in phrase.lower() for bad in invalid_keywords):\n",
    "        if not re.match(r'^\\d+(\\s+\\d+)*$', phrase):  # remove pure number phrases\n",
    "            valid_topics.append((phrase, round(score, 2)))\n",
    "\n",
    "seen = set()\n",
    "filtered_topics = []\n",
    "for topic in valid_topics:\n",
    "    if topic[0] not in seen:\n",
    "        seen.add(topic[0])\n",
    "        filtered_topics.append(topic)\n",
    "\n",
    "for i, (topic, score) in enumerate(filtered_topics[:20], start=1):\n",
    "    print(f\"{i}. {topic} (score: {score})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0561f9e-984a-4255-8295-e4bf0cef77e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "no. of days study plan : 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the breakdown of main topics, subtopics, and micro-topics:\n",
      "\n",
      "**Machine Learning**\n",
      "\n",
      "    Main Topic\n",
      "        Subtopic: Describe Machine Learning\n",
      "        Subtopic: Compare Machine Learning\n",
      "        Micro-topic: Elaborate Random Forest Regression\n",
      "        Micro-topic: Random Forest Regression\n",
      "        Micro-topic: Lasso Regression Techniques\n",
      "        Micro-topic: Univariate Regression\n",
      "        Micro-topic: Define Regression\n",
      "        Micro-topic: Regression Model\n",
      "\n",
      "**Dimensionality Reduction**\n",
      "\n",
      "    Main Topic\n",
      "        Subtopic: One Dimensionality Reduction Technique\n",
      "        Micro-topic: Dimensionality Reduction\n",
      "\n",
      "**Unsupervised Learning**\n",
      "\n",
      "    Main Topic\n",
      "        Subtopic: Unsupervised Learning Techniques\n",
      "        Micro-topic: Grouping\n",
      "        Micro-topic: Elaborate Grouping\n",
      "        Micro-topic: Differentiate Grouping\n",
      "\n",
      "**Evaluation Metrics**\n",
      "\n",
      "    Main Topic\n",
      "        Subtopic: Two Evaluation Metrics\n",
      "        Micro-topic: Variance Trade\n",
      "        Micro-topic: Reduce Overfitting\n",
      "\n",
      "**Data Science**\n",
      "\n",
      "    Main Topic\n",
      "        Subtopic: Data Science\n",
      "        Micro-topic: Assume Suitable Data\n",
      "        Micro-topic: Data\n",
      "\n",
      "**Artificial Intelligence**\n",
      "\n",
      "    Main Topic\n",
      "        Subtopic: Artificial Intelligence\n",
      "        Micro-topic: Reinforcement Learning\n",
      "        Micro-topic: Traditional Programming\n",
      "\n",
      "**Grading and Patterns**\n",
      "\n",
      "    Main Topic\n",
      "        Subtopic: Right Indicate Full Marks\n",
      "        Subtopic: Grading Models\n",
      "        Micro-topic: 2019 Pattern\n",
      "        Micro-topic: Insem .\n",
      "\n",
      "**Miscellaneous**\n",
      "\n",
      "    Main Topic\n",
      "        Subtopic: Make Suitable Diagram Wherever Necessary\n",
      "        Subtopic: Answers Q\n",
      "        Micro-topic: Q ..\n",
      "        Micro-topic: Q ..\n",
      "        Micro-topic: [] B\n",
      "        Micro-topic: [] C\n",
      "        Micro-topic: [] Q3\n",
      "        Micro-topic: 6361 ]- B\n",
      "        Micro-topic: 6188 ]- B\n",
      "        Micro-topic: 5321 Q1\n",
      "\n",
      "**Priority/Importance Estimation based on Repetition**\n",
      "\n",
      "1. Machine Learning (14.5)\n",
      "2. Dimensionality Reduction (12.25)\n",
      "3. Unsupervised Learning (11.0)\n",
      "4. Evaluation Metrics (10.5)\n",
      "5. Data Science (9.67)\n",
      "6. Artificial Intelligence (9.25)\n",
      "7. Grading and Patterns (8.2)\n",
      "8. Miscellaneous (7.6)\n",
      "\n",
      "**3-Day Plan Roadmap**\n",
      "\n",
      "Day 1:\n",
      "\n",
      "    Morning: Machine Learning (Describe, Compare, Random Forest Regression)\n",
      "    Afternoon: Dimensionality Reduction (One Technique, Dimensionality Reduction)\n",
      "\n",
      "Day 2:\n",
      "\n",
      "    Morning: Unsupervised Learning (Unsupervised Learning Techniques, Grouping, Elaborate Grouping)\n",
      "    Afternoon: Evaluation Metrics (Two Evaluation Metrics, Variance Trade, Reduce Overfitting)\n",
      "\n",
      "Day 3:\n",
      "\n",
      "    Morning: Data Science (Assume Suitable Data, Data Science)\n",
      "    Afternoon: Artificial Intelligence (Artificial Intelligence, Reinforcement Learning, Traditional Programming)\n",
      "\n",
      "**Flowchart of Topics**\n",
      "\n",
      "Here is a simple flowchart representation of the topics:\n",
      "\n",
      "Machine Learning\n",
      "    |\n",
      "    |--- Describe Machine Learning\n",
      "    |--- Compare Machine Learning\n",
      "    |--- Random Forest Regression\n",
      "    |--- Lasso Regression Techniques\n",
      "    |--- Univariate Regression\n",
      "    |--- Define Regression\n",
      "    |--- Regression Model\n",
      "\n",
      "Dimensionality Reduction\n",
      "    |\n",
      "    |--- One Dimensionality Reduction Technique\n",
      "    |--- Dimensionality Reduction\n",
      "\n",
      "Unsupervised Learning\n",
      "    |\n",
      "    |--- Unsupervised Learning Techniques\n",
      "    |--- Grouping\n",
      "    |--- Elaborate Grouping\n",
      "    |--- Differentiate Grouping\n",
      "\n",
      "Evaluation Metrics\n",
      "    |\n",
      "    |--- Two Evaluation Metrics\n",
      "    |--- Variance Trade\n",
      "    |--- Reduce Overfitting\n",
      "\n",
      "Data Science\n",
      "    |\n",
      "    |--- Assume Suitable Data\n",
      "    |--- Data Science\n",
      "\n",
      "Artificial Intelligence\n",
      "    |\n",
      "    |--- Artificial Intelligence\n",
      "    |--- Reinforcement Learning\n",
      "    |--- Traditional Programming\n",
      "\n",
      "Grading and Patterns\n",
      "    |\n",
      "    |--- Right Indicate Full Marks\n",
      "    |--- Grading Models\n",
      "    |--- 2019 Pattern\n",
      "    |--- Insem .\n",
      "\n",
      "Miscellaneous\n",
      "    |\n",
      "    |--- Make Suitable Diagram Wherever Necessary\n",
      "    |--- Answers Q\n",
      "    |--- Q ..\n",
      "    |--- Q ..\n",
      "    |--- [] B\n",
      "    |--- [] C\n",
      "    |--- [] Q3\n",
      "    |--- 6361 ]- B\n",
      "    |--- 6188 ]- B\n",
      "    |--- 5321 Q1\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "groq_api_key = \"\"\n",
    "\n",
    "client = Groq(api_key=groq_api_key)\n",
    "\n",
    "n=int(input('no. of days study plan :'))\n",
    "\n",
    "def convert_tuples_to_text(tuples):\n",
    "    output = \"\"\n",
    "    for t in tuples:\n",
    "        output += f\"{t[0]} → {t[1]}\\n\"\n",
    "    return output\n",
    "\n",
    "keywords_text = convert_tuples_to_text(filtered_topics)\n",
    "\n",
    "prompt = f\"\"\"\n",
    "From the following texts derive annd extract the important topics the topic names maybe with noise as they are scanned so figure out the topics, then fix it.And generate:\n",
    "1. A plain-text breakdown of main topics, subtopics, and micro-topics. Make sure to include all of them.\n",
    "2. A priority/importance estimation based on repetition.\n",
    "3. A {n}days plan roadmap in plain, structured, and readable format and try to cover all the topics.\n",
    "4. Create a flowchart of all the topics. Create it anyhow you can. \n",
    "Do NOT use markdown or special symbols like * or **. Format clearly using indentation and spacing. And also dont use your self messages like 'here is your result'\n",
    "\n",
    "Topics:\n",
    "{valid_topics}\n",
    "\"\"\"\n",
    "\n",
    "# Make the API call\n",
    "response = client.chat.completions.create(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "# Print response\n",
    "print(response.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
